{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "runtime_attributes": {
        "runtime_version": "2025.07"
      },
      "authorship_tag": "ABX9TyMgV1eLvTLHYpK6/3rQuN0j",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/debabratasaha-dev/custom-models/blob/main/Customize_classification_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1or7JduNofft",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e5e0e67-5131-411e-b040-e40af6afb867"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.11.13\n"
          ]
        }
      ],
      "source": [
        "!python -V"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8cec13f"
      },
      "source": [
        "# Task\n",
        "Provide the Python code to create, train, and evaluate a custom image classification model using MediaPipe Model Maker, including data preparation steps."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4b4e430d"
      },
      "source": [
        "## Install necessary libraries\n",
        "\n",
        "### Subtask:\n",
        "Install the MediaPipe Model Maker library.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c22ba012"
      },
      "source": [
        "**Reasoning**:\n",
        "Install the MediaPipe Model Maker library using pip.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ef01bac3"
      },
      "source": [
        "!pip install mediapipe-model-maker"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47a2c4a3"
      },
      "source": [
        "## Prepare data\n",
        "\n",
        "### Subtask:\n",
        "Download and prepare the image dataset for training and evaluation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0c3a6fd8"
      },
      "source": [
        "**Reasoning**:\n",
        "Download and extract the dataset, then create and split the dataset using MediaPipe Model Maker.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q model_training_data.zip"
      ],
      "metadata": {
        "id": "FUkuP_V34eD_"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2be014e"
      },
      "source": [
        "import tensorflow as tf\n",
        "import mediapipe as mp\n",
        "\n",
        "from mediapipe_model_maker import image_classifier\n",
        "\n",
        "# Create a Dataset object\n",
        "dataset_path = 'model_training_data'\n",
        "data = image_classifier.Dataset.from_folder(dataset_path)\n",
        "\n",
        "# Split the dataset\n",
        "train_data, remaining_data = data.split(0.8)\n",
        "validation_data, test_data = remaining_data.split(0.5)\n",
        "\n",
        "print(f\"Training dataset size: {len(train_data)}\")\n",
        "print(f\"Validation dataset size: {len(validation_data)}\")\n",
        "print(f\"Testing dataset size: {len(test_data)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train The Model"
      ],
      "metadata": {
        "id": "xKrq1Y4NsIGH"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4845c96f"
      },
      "source": [
        "# Define model options\n",
        "hparams = image_classifier.HParams(export_dir=\"operations_model\")\n",
        "options = image_classifier.ImageClassifierOptions(supported_model=image_classifier.SupportedModels.MOBILENET_V2,\n",
        "                                                  hparams = hparams)\n",
        "\n",
        "# Create the model\n",
        "model = image_classifier.ImageClassifier.create(\n",
        "    train_data=train_data,\n",
        "    validation_data=validation_data,\n",
        "    options=options\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2280094d"
      },
      "source": [
        "**Reasoning**:\n",
        "The first step is to load the data from the CSV file into a pandas DataFrame and display the first few rows to understand its structure.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc = model.evaluate(test_data, batch_size=1)\n",
        "print(f\"Test loss:{loss}, Test accuracy:{acc}\")"
      ],
      "metadata": {
        "id": "zXyxpY4CLzdl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Export the model bundle.\n",
        "model.export_model()"
      ],
      "metadata": {
        "id": "gtlo9ZhxM4Nr"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Rename the file to be more descriptive.\n",
        "!cp operations_model/model.tflite operations.tflite"
      ],
      "metadata": {
        "id": "M23XP6sqOzQa"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"operations.tflite\")"
      ],
      "metadata": {
        "id": "gQHKpNq9PSXL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "\n",
        "!wget -q -O photo.jpg \"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSaImd0YXAvyZMdppmvDosACD_cEU9pkWktoA&s\"\n",
        "\n",
        "img = cv2.imread(\"photo.jpg\")\n",
        "cv2_imshow(img)"
      ],
      "metadata": {
        "id": "y8-DwtpLp7Sa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports neccessary modules.\n",
        "import mediapipe as mp\n",
        "from mediapipe.tasks import python\n",
        "from mediapipe.tasks.python import vision\n",
        "import os\n",
        "# Create a GestureRecognizer object.\n",
        "model_path = os.path.abspath(\"operations.tflite\")\n",
        "classifier = vision.ImageClassifier.create_from_model_path(model_path)\n",
        "\n",
        "# Load the input image.\n",
        "image = mp.Image.create_from_file('photo.jpg')\n",
        "\n",
        "# Run gesture recognition.\n",
        "classification_result = classifier.classify(image)\n",
        "\n",
        "print(classification_result)\n",
        "# Display the most likely gesture.\n",
        "top_category = classification_result.classifications[0].categories[0]\n",
        "print(f\"Operatoin detected: {top_category.category_name} ({top_category.score})\")"
      ],
      "metadata": {
        "id": "iiXfexYg0fph"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}